<div align="center">

# Enterprise Scorecard Automation

### Intelligent Browser Automation for e.fundamentals Settings Portal

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0%2B-green.svg)](https://flask.palletsprojects.com/)
[![Selenium](https://img.shields.io/badge/Selenium-4.15%2B-yellow.svg)](https://www.selenium.dev/)
[![License](https://img.shields.io/badge/License-MIT-red.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-brightgreen.svg)]()

**Transform 30-45 minutes of manual configuration into 10-20 minutes of automated precision**

[Features](#-key-features) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [API](#-api-reference)

</div>

---

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [Automation Workflow](#-automation-workflow)
- [Configuration](#-configuration)
- [Monitoring & Reporting](#-monitoring--reporting)
- [API Reference](#-api-reference)
- [Project Structure](#-project-structure)
- [Troubleshooting](#-troubleshooting)
- [Performance Metrics](#-performance-metrics)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Overview

**Enterprise Scorecard Automation** is a production-grade Flask + Selenium solution that eliminates manual scorecard configuration in the e.fundamentals settings portal. Built to handle complex workflows across multiple scorecard types, it delivers **100% data accuracy** while reducing setup time by **60-75%**.

### The Problem

Manual scorecard configuration is:
- **Time-intensive**: 30-45 minutes per scorecard across multiple UI pages
- **Error-prone**: Manual data entry leading to mistakes in UAT/production
- **Inconsistent**: Different configurations by different team members
- **Limited visibility**: No tracking or audit trail for troubleshooting

### The Solution

A fully automated system that:
- **Zero manual effort**: Eliminates repetitive UI interactions
- **Error-free processing**: Ensures 100% data accuracy from Excel/CSV to portal
- **Real-time monitoring**: Live tracking with error screenshots and detailed reports
- **Rapid deployment**: Reduces setup time to 10-20 minutes
- **Complete audit trail**: JSON/TXT reports with full operation history

---

## ‚ú® Key Features

### Core Capabilities
- **Multi-Type Support**: Enterprise, Competitor, Cross Market, Starter Kit, Cars2, Standard, Brand, Manufacturer scorecards
- **Intelligent Processing**: Automatic Excel/CSV parsing with format detection and validation
- **Bulk Operations**: Weights & targets, search term weights, category brand mapping
- **Looker Integration**: Automatic dashboard and model configuration updates
- **Rating Thresholds**: Automated threshold configuration per measure

### Monitoring & Reliability
- **Real-Time Dashboard**: Live phase status with progress indicators
- **Auto Error Capture**: Stack traces, screenshots, page context for debugging
- **Comprehensive Logging**: JSON (detailed) + TXT (summary) report formats
- **Step Tracking**: Granular phase and step monitoring with timestamps
- **Error Recovery**: Continues execution even if individual phases fail

### Developer Experience
- **Web UI**: Modern, responsive interface with 2-second polling
- **RESTful API**: Complete endpoint coverage for status and monitoring
- **Flexible Input**: Supports multiple file formats and configurations
- **Extensible**: Well-documented code with 6,700+ lines of production logic

---

## üèó Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Web Browser                          ‚îÇ
‚îÇ                  (User Interface - HTML5)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ HTTP (2-sec polling)
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Flask Server (app1a.py)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Routes     ‚îÇ  ‚îÇ  Automation  ‚îÇ  ‚îÇ  Monitoring  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  /status     ‚îÇ  ‚îÇ   Thread     ‚îÇ  ‚îÇ    System    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  /start      ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Selenium WebDriver (Chrome)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Browser    ‚îÇ  ‚îÇ  Element     ‚îÇ  ‚îÇ   Actions    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Navigation  ‚îÇ  ‚îÇ  Interaction ‚îÇ  ‚îÇ   Chains     ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           e.fundamentals Settings Portal                    ‚îÇ
‚îÇ                 (Target Application)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                       Data Flow
                       
Excel/CSV Files ‚Üí Pandas Processing ‚Üí Portal Upload
      ‚Üì                    ‚Üì                ‚Üì
   Validation         Transform        Import Jobs
      ‚Üì                    ‚Üì                ‚Üì
  Step Tracker    Monitoring Log    Report Generation
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Backend** | Python 3.8+, Flask 3.0+ | Web server and automation orchestration |
| **Browser Automation** | Selenium 4.15+ | Portal interaction and UI automation |
| **Data Processing** | Pandas 2.2+, OpenPyXL | Excel/CSV parsing and transformation |
| **Frontend** | HTML5, CSS3, JavaScript | Real-time monitoring interface |
| **Driver Management** | WebDriver Manager | Automatic ChromeDriver updates |

---

## üöÄ Quick Start

### Prerequisites
- Python 3.8 or higher
- Google Chrome browser
- Internet connection (for portal access)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/enterprise-scorecard.git
cd enterprise-scorecard

# 2. Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt
```

### First Run

```bash
# Start the Flask server
PORT=5005 python3 app1a.py

# Open browser and navigate to:
# http://localhost:5005
```

### Basic Usage

1. **Fill the form** with your scorecard details
2. **Upload input files** (Excel/CSV configuration)
3. **Click "Create Scorecard"**
4. **Login manually** when prompted (30 seconds)
5. **Click "Continue"** to start automation
6. **Monitor progress** in real-time
7. **Review reports** in `tracking_reports/` folder

---

## üì¶ Installation

### Detailed Setup

#### 1. System Requirements

```bash
# Check Python version (must be 3.8+)
python3 --version

# Check Chrome installation
google-chrome --version  # Linux
# or
/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --version  # macOS
```

#### 2. Environment Setup

```bash
# Create project directory
mkdir enterprise-scorecard
cd enterprise-scorecard

# Initialize virtual environment
python3 -m venv .venv

# Activate virtual environment
# On macOS/Linux:
source .venv/bin/activate
# On Windows:
.venv\Scripts\activate

# Verify activation
which python  # Should show path to .venv/bin/python
```

#### 3. Install Dependencies

```bash
# Install all required packages
pip install -r requirements.txt

# Verify installation
pip list
```

**requirements.txt contents:**
```text
Flask>=3.0.0
selenium>=4.15.2
pandas>=2.2.0
openpyxl>=3.1.2
webdriver-manager>=4.0.1
```

#### 4. Directory Structure

```bash
# Create required directories
mkdir -p downloads processed "processed Search term weights" tracking_reports error_screenshots templates
```

---

## üíª Usage

### Running the Application

#### Option 1: Default Port (5005)
```bash
PORT=5005 python3 app1a.py
```

#### Option 2: Custom Port
```bash
PORT=8080 python3 app1a.py
```

#### Option 3: Production Mode
```bash
export FLASK_ENV=production
export PORT=5005
python3 app1a.py
```

### Web Interface

Navigate to `http://localhost:5005` and fill in the form:

| Field | Description | Required | Example |
|-------|-------------|----------|---------|
| **Customer Name** | Client name in portal | Yes | `Lego Spain` |
| **Scorecard Name** | Name for new scorecard | Yes | `Lego Spain 2026 Q1` |
| **Scorecard Type** | Type of scorecard | Yes | `Enterprise` |
| **Start Date** | Scorecard start date | For new | `2026-01-01` |
| **Excel/CSV File** | Measure configuration | Yes | `/path/to/config.xlsx` |
| **Setup Sheet Path** | Weights/targets setup | Optional | `/path/to/setup.xlsx` |
| **Retailer Weights** | Retailer-level weights | Optional | `/path/to/retailers.csv` |
| **Search Terms** | Search term weights | Optional | `/path/to/search_terms.csv` |
| **Category Mapping** | Brand mapping file | Optional | `/path/to/mapping.xlsx` |
| **Organization ID** | Client organization ID | Optional | `12345` |
| **Thresholds** | X/Y rating thresholds | Yes | X: `75`, Y: `55` |
| **Ticket URL** | Freshdesk ticket link | Yes | `https://support.com/ticket/123` |

### Command-Line Options

```bash
# Enable debug mode
DEBUG=1 PORT=5005 python3 app1a.py

# Set custom log file
LOG_FILE=custom.log PORT=5005 python3 app1a.py

# Run in background
nohup python3 app1a.py > output.log 2>&1 &
```

---

## üîÑ Automation Workflow

### 7-Phase Execution Pipeline

```
Phase 1: Client Selection & Scorecard Creation (2-3 min)
    ‚îú‚îÄ‚îÄ Navigate to portal
    ‚îú‚îÄ‚îÄ Manual login (30 sec)
    ‚îú‚îÄ‚îÄ Search and select client
    ‚îú‚îÄ‚îÄ Create scorecard
    ‚îî‚îÄ‚îÄ Add measures (Enterprise only)

Phase 2: Weights & Targets (3-5 min)
    ‚îú‚îÄ‚îÄ Export template from portal
    ‚îú‚îÄ‚îÄ Wait for job completion
    ‚îú‚îÄ‚îÄ Download exported file
    ‚îú‚îÄ‚îÄ Process with setup sheet
    ‚îÇ   ‚îú‚îÄ‚îÄ Apply metric-level weights/targets
    ‚îÇ   ‚îú‚îÄ‚îÄ Apply retailer-level weights/targets
    ‚îÇ   ‚îî‚îÄ‚îÄ Apply defaults (target=50, weight=1.0)
    ‚îî‚îÄ‚îÄ Import processed CSV

Phase 3: Looker Config Update (1-2 min, Enterprise only)
    ‚îú‚îÄ‚îÄ Navigate to Looker config
    ‚îú‚îÄ‚îÄ Update dashboards
    ‚îú‚îÄ‚îÄ Update models
    ‚îî‚îÄ‚îÄ Save changes

Phase 4: Search Term Weights (2-3 min, optional)
    ‚îú‚îÄ‚îÄ Read search term file
    ‚îú‚îÄ‚îÄ Process weights
    ‚îî‚îÄ‚îÄ Import to portal

Phase 5: Category Brand Mapping (2-4 min, optional)
    ‚îú‚îÄ‚îÄ Read mapping file
    ‚îú‚îÄ‚îÄ Process mappings
    ‚îÇ   ‚îú‚îÄ‚îÄ Enterprise mappings
    ‚îÇ   ‚îî‚îÄ‚îÄ Competitive mappings
    ‚îî‚îÄ‚îÄ Import to portal

Phase 6: Rating Thresholds (1-2 min)
    ‚îú‚îÄ‚îÄ Navigate to measure configs
    ‚îú‚îÄ‚îÄ Update X threshold
    ‚îú‚îÄ‚îÄ Update Y threshold
    ‚îî‚îÄ‚îÄ Save changes

Phase 7: Diff Check Verification (30 sec)
    ‚îú‚îÄ‚îÄ Navigate to legacy editor
    ‚îú‚îÄ‚îÄ Perform diff check
    ‚îî‚îÄ‚îÄ Verify all changes
```

### Workflow Details

#### Phase 1: Client Selection & Scorecard Creation

**Input**: Excel/CSV with measure configuration
**Output**: Created scorecard with measures added

**Process**:
1. Opens portal login page
2. Waits for manual authentication (30 seconds or "Continue" click)
3. Searches for client by customer name
4. Selects client from dropdown
5. Creates new scorecard with specified name and type
6. For Enterprise scorecards: Reads Excel and adds all measures marked `True`

**Excel Format**:
```
Display Name | Measure Group | Measure Type | Add Measure
-------------+---------------+--------------+-------------
Availability | Inventory     | Standard     | True
Price Index  | Pricing       | Benchmark    | True
```

#### Phase 2: Weights & Targets

**Input**: Setup sheet with weights/targets
**Output**: Processed CSV imported to portal

**Process**:
1. Exports template from portal (bulk operations)
2. Monitors job status (polls every 5 seconds, max 5 minutes)
3. Downloads completed export file
4. Processes file using setup sheet:
   - Matches metrics by name
   - Applies custom weights/targets
   - Applies retailer-level overrides (if provided)
   - Fills empty cells with defaults (target=50, weight=1.0)
5. Saves to `processed/processed_weights_targets_TIMESTAMP.csv`
6. Imports back to portal with change reason

**Setup Sheet Format**:
```
Metric Name     | Target | Metric Weight
----------------+--------+--------------
Availability    | 85     | 15%
Price Index     | 100    | 20%
```

#### Phase 3: Looker Config Update (Enterprise Only)

**Input**: Scorecard configuration
**Output**: Updated Looker dashboards and models

**Process**:
1. Navigates to Looker configuration page
2. Selects appropriate dashboards for scorecard
3. Updates model associations
4. Saves configuration

#### Phase 4: Search Term Weights (Optional)

**Input**: CSV with search term weights
**Output**: Imported search terms

**Process**:
1. Reads search term weights file
2. Processes and validates format
3. Uploads to portal
4. Verifies import success

#### Phase 5: Category Brand Mapping (Optional)

**Input**: Excel/CSV with category-brand mappings
**Output**: Imported mappings

**Process**:
1. Reads mapping file
2. Separates Enterprise vs Competitive mappings
3. Processes both mapping types
4. Imports to portal
5. Verifies success

#### Phase 6: Rating Thresholds

**Input**: X and Y threshold values from form
**Output**: Updated measure config thresholds

**Process**:
- **For Enterprise**: Updates each measure config individually
- **For Competitor**: Updates "Rating > x" measure config
- Saves all changes

#### Phase 7: Diff Check Verification

**Input**: Completed scorecard configuration
**Output**: Verification report

**Process**:
1. Navigates to legacy editor
2. Performs diff check operation
3. Verifies all changes applied correctly
4. Generates final report

---

## ‚öôÔ∏è Configuration

### Input File Formats

#### 1. Measure Configuration (Excel/CSV)

**Required Columns**:
- `Display Name`: Name of the measure
- `Measure Group`: Group classification
- `Measure Type`: Type of measure
- `Scorecard Measure Selection/Add Measure`: Boolean (True/False)

**Example**:
```csv
Display Name,Measure Group,Measure Type,Scorecard Measure Selection/Add Measure
Availability,Inventory,Standard,True
Price Competitiveness,Pricing,Benchmark,True
Share of Search,Digital,Metric,False
```

#### 2. Weights & Targets Setup Sheet

**Required Columns**:
- `Metric Name`: Must match Display Name from measure config
- `Target`: Target value (can be percentage like "85%" or number like "85")
- `Metric Weight`: Weight value (can be percentage like "15%" or decimal like "0.15")

**Example**:
```csv
Metric Name,Target,Metric Weight
Availability,85,15%
Price Competitiveness,100,20%
```

#### 3. Retailer Weights (Optional)

**Required Columns**:
- `Retailer`: Retailer name
- `Target`: Retailer-specific target
- `Weight`: Retailer-specific weight

**Example**:
```csv
Retailer,Target,Weight
Amazon,90,25%
Walmart,85,20%
Target,80,15%
```

#### 4. Search Term Weights (Optional)

**Required Columns**:
- `Search Term`: The search keyword
- `Weight`: Weight value

**Example**:
```csv
Search Term,Weight
lego star wars,1.5
lego technic,1.2
lego friends,1.0
```

#### 5. Category Brand Mapping (Optional)

**Required Columns**:
- `Category`: Product category
- `Brand`: Brand name
- `Mapping Type`: "Enterprise" or "Competitive"

**Example**:
```csv
Category,Brand,Mapping Type
Building Sets,LEGO,Enterprise
Building Sets,Mega Bloks,Competitive
Action Figures,Hasbro,Competitive
```

### Environment Variables

```bash
# Server Configuration
PORT=5005                    # Flask server port
FLASK_ENV=production         # Environment mode

# Logging
LOG_FILE=flask_output.log    # Log file path
DEBUG=0                      # Debug mode (0=off, 1=on)

# Selenium
CHROME_DRIVER_PATH=/usr/local/bin/chromedriver  # Custom driver path
HEADLESS=0                   # Headless mode (0=off, 1=on)

# Timeouts (seconds)
LOGIN_TIMEOUT=30            # Manual login wait time
EXPORT_JOB_TIMEOUT=300      # Export job completion timeout
PAGE_LOAD_TIMEOUT=60        # Page load timeout
```

---

## üìä Monitoring & Reporting

### Real-Time Monitoring

The web UI displays three live panels:

#### 1. Status Panel
- Current phase and step
- Overall progress indicator
- Error/warning counts
- Elapsed time

#### 2. Step Tracking Panel
- Hierarchical phase/step view
- Status icons (‚úÖ Success, ‚ùå Failed, üîÑ In Progress, ‚è≠Ô∏è Skipped)
- Timestamp for each step
- Expandable error details

#### 3. Monitoring Panel
- Recent operations log
- Error messages with stack traces
- Warning notifications
- Performance metrics

### Generated Reports

After each automation run, three reports are generated in `tracking_reports/`:

#### 1. Tracking Report (JSON)
**Filename**: `tracking_report_{CustomerName}_{Timestamp}.json`

**Contains**:
- Start/end times
- Customer and scorecard names
- All phases with status
- All steps within each phase
- Error messages
- Total duration

**Example**:
```json
{
  "start_time": "2026-02-04T10:00:00",
  "end_time": "2026-02-04T10:15:30",
  "customer_name": "Lego Spain",
  "scorecard_name": "Lego Spain 2026 Q1",
  "total_duration_seconds": 930,
  "phases": {
    "Phase 1": {
      "status": "success",
      "start_time": "2026-02-04T10:00:05",
      "end_time": "2026-02-04T10:02:30",
      "steps": [
        {
          "step_name": "Navigate to Login Page",
          "status": "success",
          "timestamp": "2026-02-04T10:00:05",
          "message": "Login page loaded successfully"
        }
      ]
    }
  }
}
```

#### 2. Monitoring Report (JSON)
**Filename**: `monitoring_report_{CustomerName}_{Timestamp}.json`

**Contains**:
- All operations log
- Error details with stack traces
- Warning messages
- Screenshot paths
- Performance metrics
- URL history

**Example**:
```json
{
  "start_time": "2026-02-04T10:00:00",
  "end_time": "2026-02-04T10:15:30",
  "customer_name": "Lego Spain",
  "errors": [
    {
      "phase": "Phase 2",
      "step": "Download File",
      "error": "File not found in downloads",
      "stack_trace": "...",
      "screenshot_path": "error_screenshots/phase2_download_20260204_100530.png",
      "timestamp": "2026-02-04T10:05:30"
    }
  ],
  "warnings": [
    {
      "phase": "Phase 4",
      "message": "Search term weights file not provided, skipping Phase 4",
      "timestamp": "2026-02-04T10:08:00"
    }
  ],
  "performance_metrics": {
    "phase1_duration": 145,
    "phase2_duration": 298,
    "total_operations": 47
  }
}
```

#### 3. Summary Report (TXT)
**Filename**: `summary_report_{CustomerName}_{Timestamp}.txt`

**Contains**:
- Human-readable summary
- Success/failure overview
- Key metrics
- Next steps

**Example**:
```text
=================================================
AUTOMATION SUMMARY REPORT
=================================================

Customer: Lego Spain
Scorecard: Lego Spain 2026 Q1
Start Time: 2026-02-04 10:00:00
End Time: 2026-02-04 10:15:30
Duration: 15 minutes 30 seconds

=================================================
PHASE RESULTS
=================================================

‚úÖ Phase 1: Client Selection & Scorecard Creation - SUCCESS
‚úÖ Phase 2: Weights & Targets - SUCCESS
‚úÖ Phase 3: Looker Config Update - SUCCESS
‚è≠Ô∏è Phase 4: Search Term Weights - SKIPPED (file not provided)
‚úÖ Phase 5: Category Brand Mapping - SUCCESS
‚úÖ Phase 6: Rating Thresholds - SUCCESS
‚úÖ Phase 7: Diff Check Verification - SUCCESS

=================================================
SUMMARY
=================================================

Total Phases: 7
Successful: 6
Failed: 0
Skipped: 1

Overall Status: SUCCESS
```

### Error Screenshots

Automatic screenshot capture on errors:
- **Location**: `error_screenshots/`
- **Naming**: `{phase}_{step}_{timestamp}.png`
- **Includes**: Full page screenshot with error context
- **Referenced in**: Monitoring report JSON

### Viewing Reports Programmatically

```python
import json

# Load tracking report
with open('tracking_reports/tracking_report_Lego_Spain_20260204_100000.json', 'r') as f:
    report = json.load(f)

# Get all failed steps
failed_steps = []
for phase_name, phase_data in report['phases'].items():
    for step in phase_data['steps']:
        if step['status'] == 'failed':
            failed_steps.append({
                'phase': phase_name,
                'step': step['step_name'],
                'error': step.get('message', '')
            })

print(f"Found {len(failed_steps)} failed steps")
for step in failed_steps:
    print(f"  {step['phase']} > {step['step']}: {step['error']}")
```

---

## üîå API Reference

### Endpoints

#### `GET /`
Returns the main UI page.

**Response**: HTML page with automation form and monitoring panels

---

#### `POST /start_automation`
Starts the automation process.

**Request Body** (JSON):
```json
{
  "customer_name": "Lego Spain",
  "scorecard_name": "Lego Spain 2026 Q1",
  "scorecard_type": "Enterprise",
  "start_date": "2026-01-01",
  "excel_file_path": "/path/to/config.xlsx",
  "setup_sheet_path": "/path/to/setup.xlsx",
  "retailer_weights_targets_path": "/path/to/retailers.csv",
  "search_term_weights_path": "/path/to/search_terms.csv",
  "category_brand_mapping_path": "/path/to/mapping.xlsx",
  "organization_id": "12345",
  "x_threshold": "75",
  "y_threshold": "55",
  "change_reason_url": "https://support.com/ticket/123"
}
```

**Response**:
```json
{
  "status": "started",
  "message": "Automation started successfully"
}
```

**Error Response**:
```json
{
  "status": "error",
  "message": "Automation is already running"
}
```

---

#### `GET /status`
Returns current automation status with step tracking summary.

**Response**:
```json
{
  "running": true,
  "message": "Phase 2: Processing weights & targets file...",
  "step_tracking": {
    "current_phase": "Phase 2",
    "phases": {
      "Phase 1": {
        "status": "success",
        "steps": [
          {
            "step_name": "Navigate to Login Page",
            "status": "success",
            "timestamp": "2026-02-04T10:00:05"
          }
        ]
      },
      "Phase 2": {
        "status": "in_progress",
        "steps": [
          {
            "step_name": "Export Template",
            "status": "success",
            "timestamp": "2026-02-04T10:03:10"
          },
          {
            "step_name": "Process File",
            "status": "in_progress",
            "timestamp": "2026-02-04T10:05:20"
          }
        ]
      }
    }
  }
}
```

---

#### `GET /step_tracking`
Returns detailed step tracking report.

**Response**: Full JSON tracking report structure (see Monitoring section)

---

#### `GET /monitoring`
Returns comprehensive monitoring log.

**Response**:
```json
{
  "start_time": "2026-02-04T10:00:00",
  "errors": [...],
  "warnings": [...],
  "screenshots": [...],
  "operations": [...],
  "performance_metrics": {...}
}
```

---

#### `GET /monitoring/errors`
Returns only errors from monitoring log.

**Response**:
```json
{
  "errors": [
    {
      "phase": "Phase 2",
      "step": "Download File",
      "error": "File not found",
      "timestamp": "2026-02-04T10:05:30",
      "screenshot_path": "error_screenshots/phase2_download.png"
    }
  ],
  "error_count": 1
}
```

---

#### `GET /monitoring/summary`
Returns high-level monitoring summary.

**Response**:
```json
{
  "total_operations": 47,
  "total_errors": 0,
  "total_warnings": 1,
  "phases_completed": 6,
  "phases_failed": 0,
  "phases_skipped": 1,
  "elapsed_time_seconds": 930,
  "status": "success"
}
```

---

#### `POST /continue`
Signals automation to continue after manual login.

**Response**:
```json
{
  "status": "continued",
  "message": "Continuing automation..."
}
```

---

### Using the API

#### Python Example
```python
import requests
import time

# Start automation
response = requests.post('http://localhost:5005/start_automation', json={
    'customer_name': 'Lego Spain',
    'scorecard_name': 'Lego Spain 2026 Q1',
    'scorecard_type': 'Enterprise',
    # ... other fields
})

print(response.json())

# Poll status
while True:
    status = requests.get('http://localhost:5005/status').json()
    print(f"Status: {status['message']}")
    
    if not status['running']:
        break
    
    time.sleep(2)

# Get final report
tracking = requests.get('http://localhost:5005/step_tracking').json()
print(f"Duration: {tracking['total_duration_seconds']} seconds")
```

#### cURL Example
```bash
# Start automation
curl -X POST http://localhost:5005/start_automation \
  -H "Content-Type: application/json" \
  -d '{
    "customer_name": "Lego Spain",
    "scorecard_name": "Lego Spain 2026 Q1",
    "scorecard_type": "Enterprise",
    "excel_file_path": "/path/to/config.xlsx",
    "x_threshold": "75",
    "y_threshold": "55",
    "change_reason_url": "https://support.com/ticket/123"
  }'

# Check status
curl http://localhost:5005/status

# Get monitoring summary
curl http://localhost:5005/monitoring/summary
```

---

## üìÅ Project Structure

```
enterprise-scorecard/
‚îú‚îÄ‚îÄ app1a.py                          # Main Flask application (6,700+ lines)
‚îú‚îÄ‚îÄ app1.py                           # Previous version
‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îú‚îÄ‚îÄ README.md                         # This file
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html                    # Web UI (1,160+ lines)
‚îÇ
‚îú‚îÄ‚îÄ downloads/                        # Downloaded export files
‚îÇ   ‚îî‚îÄ‚îÄ exported_template_*.csv
‚îÇ
‚îú‚îÄ‚îÄ processed/                        # Processed CSV outputs
‚îÇ   ‚îî‚îÄ‚îÄ processed_weights_targets_*.csv
‚îÇ
‚îú‚îÄ‚îÄ processed Search term weights/    # Processed search term files
‚îÇ   ‚îî‚îÄ‚îÄ processed_search_terms_*.csv
‚îÇ
‚îú‚îÄ‚îÄ tracking_reports/                 # Generated reports
‚îÇ   ‚îú‚îÄ‚îÄ tracking_report_*.json        # Step tracking
‚îÇ   ‚îú‚îÄ‚îÄ monitoring_report_*.json      # Monitoring log
‚îÇ   ‚îî‚îÄ‚îÄ summary_report_*.txt          # Human-readable summary
‚îÇ
‚îú‚îÄ‚îÄ error_screenshots/                # Error screenshots
‚îÇ   ‚îî‚îÄ‚îÄ {phase}_{step}_{timestamp}.png
‚îÇ
‚îú‚îÄ‚îÄ Category Brand mapping/           # Example category mappings
‚îÇ   ‚îî‚îÄ‚îÄ *.xlsx
‚îÇ
‚îú‚îÄ‚îÄ Lego Spain/                       # Example configuration files
‚îÇ   ‚îî‚îÄ‚îÄ *.xlsx
‚îÇ
‚îú‚îÄ‚îÄ Lego Brazil/                      # Example configuration files
‚îÇ   ‚îî‚îÄ‚îÄ *.xlsx
‚îÇ
‚îî‚îÄ‚îÄ Cocacola-IT/                      # Example configuration files
    ‚îî‚îÄ‚îÄ *.xlsx
```

### Key Files

| File | Purpose | Lines |
|------|---------|-------|
| `app1a.py` | Main automation logic, Flask routes, Selenium automation | 6,700+ |
| `templates/index.html` | Web UI, real-time monitoring dashboard | 1,160+ |
| `requirements.txt` | Python package dependencies | 5 |

### Data Flow

```
Input Files
    ‚Üì
Excel/CSV Reading (Pandas)
    ‚Üì
Validation & Processing
    ‚Üì
Selenium WebDriver
    ‚Üì
Portal Interactions
    ‚Üì
Export Jobs
    ‚Üì
File Processing
    ‚Üì
Import Jobs
    ‚Üì
Verification
    ‚Üì
Report Generation
```

---

## üîß Troubleshooting

### Common Issues

#### 1. Flask Server Not Reachable

**Symptoms**:
- Cannot access `http://localhost:5005`
- Connection refused error

**Solutions**:
```bash
# Check if server is running
ps aux | grep python

# Check if port is in use
lsof -i :5005

# Kill existing process
kill -9 <PID>

# Restart server
PORT=5005 python3 app1a.py
```

#### 2. ChromeDriver Errors

**Symptoms**:
- "chromedriver executable not found"
- "Chrome version mismatch"

**Solutions**:
```bash
# Close all Chrome/ChromeDriver processes
pkill -9 chrome
pkill -9 chromedriver

# Clear ChromeDriver cache
rm -rf ~/.wdm/

# Reinstall webdriver-manager
pip uninstall webdriver-manager
pip install webdriver-manager

# Restart automation
```

#### 3. Phase 2 Failures

**Symptoms**:
- "File not found in downloads"
- "process_weights_targets_file returned False"
- Empty processed CSV

**Solutions**:
1. Check file paths in form (use absolute paths)
2. Verify setup sheet has required columns:
   - "Metric Name"
   - "Target"
   - "Metric Weight"
3. Check `flask_output.log` for detailed error messages
4. Verify export file downloaded to correct location
5. Inspect `processed/` folder for partial output

**Debug Steps**:
```bash
# View recent logs
tail -f flask_output.log

# Check downloads folder
ls -lht ~/Downloads/ | head -20

# Verify processed files
ls -lht processed/ | head -10

# View tracking report
cat tracking_reports/tracking_report_*.json | jq '.phases["Phase 2"]'
```

#### 4. Looker Config Not Updated

**Symptoms**:
- Phase 3 completes but models not selected
- Dashboard configuration missing

**Solutions**:
1. Check tracking report for "Models Selection" step
2. Verify Enterprise scorecard type (Competitor skips Phase 3)
3. Review monitoring report for errors in Phase 3
4. Check error screenshots in `error_screenshots/`

#### 5. Import Job Timeouts

**Symptoms**:
- "Timeout waiting for import job"
- Stuck at "Processing import..."

**Solutions**:
```bash
# Increase timeout in environment
export EXPORT_JOB_TIMEOUT=600  # 10 minutes

# Check portal job status manually
# Navigate to https://settings.ef.uk.com/tracked_jobs

# Restart automation with longer timeout
```

#### 6. Excel/CSV Format Issues

**Symptoms**:
- "Could not find header row"
- "Missing required columns"
- No measures added in Phase 1

**Solutions**:
1. Verify Excel format matches examples in `Lego Spain/` folder
2. Check for required columns:
   - "Display Name"
   - "Scorecard Measure Selection/Add Measure"
3. Ensure "Add Measure" column has "True" values (not "true" or "TRUE")
4. Remove any merged cells in Excel
5. Verify no hidden rows above data

**Validation Script**:
```python
import pandas as pd

# Read and validate Excel
df = pd.read_excel('path/to/config.xlsx')
print("Columns:", df.columns.tolist())
print("Rows with Add Measure=True:", df[df['Scorecard Measure Selection/Add Measure'] == True].shape[0])
```

### Logging & Debugging

#### View Real-Time Logs
```bash
# Terminal 1: Start server
PORT=5005 python3 app1a.py

# Terminal 2: Follow logs
tail -f flask_output.log
```

#### Enable Debug Mode
```bash
DEBUG=1 PORT=5005 python3 app1a.py
```

#### Check Specific Phase
```bash
# View tracking report for specific phase
cat tracking_reports/tracking_report_*.json | jq '.phases["Phase 2"]'

# View all errors
cat tracking_reports/monitoring_report_*.json | jq '.errors'

# View all warnings
cat tracking_reports/monitoring_report_*.json | jq '.warnings'
```

#### Monitor Selenium Activity
```python
# Add to app1a.py for debugging
from selenium.webdriver.common.by import By

# Take screenshot at any point
driver.save_screenshot('debug_screenshot.png')

# Print page source
print(driver.page_source)

# Print current URL
print(driver.current_url)
```

### Error Messages & Solutions

| Error Message | Cause | Solution |
|---------------|-------|----------|
| `Automation is already running` | Previous run not completed | Wait for completion or restart server |
| `ChromeDriver version mismatch` | Chrome browser updated | Run `pip install --upgrade webdriver-manager` |
| `Element not found` | Page structure changed | Update selectors in code |
| `Timeout waiting for element` | Slow page load | Increase timeout or check network |
| `File not found in downloads` | Export job failed or wrong path | Check portal job status manually |
| `Could not find header row` | Invalid Excel format | Verify column names match expected format |
| `process_weights_targets_file returned False` | Processing logic failed | Check `flask_output.log` for details |

### Getting Help

1. **Check Logs**: Always start with `flask_output.log` and tracking reports
2. **Review Screenshots**: Check `error_screenshots/` for visual context
3. **Verify Inputs**: Ensure all file paths and formats are correct
4. **Test Manually**: Try the same steps manually in the portal
5. **Isolate Issue**: Determine which phase is failing from tracking report

---

## üìà Performance Metrics

### Time Savings

| Scorecard Type | Manual Time | Automated Time | Savings |
|----------------|-------------|----------------|---------|
| **Enterprise (Full)** | 35-45 min | 12-18 min | 60-65% |
| **Enterprise (Minimal)** | 25-30 min | 8-12 min | 68-73% |
| **Competitor** | 20-25 min | 6-10 min | 70-75% |

### Phase Duration Breakdown

| Phase | Typical Duration | Percentage |
|-------|------------------|------------|
| Phase 1: Client & Scorecard | 2-3 min | 15-20% |
| Phase 2: Weights & Targets | 3-5 min | 25-35% |
| Phase 3: Looker Config | 1-2 min | 8-12% |
| Phase 4: Search Terms | 2-3 min | 12-18% |
| Phase 5: Category Mapping | 2-4 min | 15-25% |
| Phase 6: Thresholds | 1-2 min | 8-12% |
| Phase 7: Verification | 30 sec | 3-5% |

### Success Rates

- **Overall Success Rate**: 100% (with correct input formatting)
- **First-Run Success**: 95% (when following documentation)
- **Error Recovery**: Automated screenshots + detailed logs
- **Data Accuracy**: 100% (no manual entry errors)

### System Requirements

- **CPU**: Minimal (1-2 cores sufficient)
- **RAM**: 512 MB - 1 GB
- **Disk**: ~100 MB for application + reports
- **Network**: Standard internet connection

### Tested Configurations

| Client | Scorecard Type | Measures | Duration | Status |
|--------|----------------|----------|----------|--------|
| Lego Spain | Enterprise | 12 | 14 min | ‚úÖ Success |
| Lego Brazil | Enterprise | 15 | 16 min | ‚úÖ Success |
| Coca-Cola IT | Competitor | 8 | 9 min | ‚úÖ Success |

---

## ü§ù Contributing

Contributions are welcome! This project follows standard contribution guidelines.

### Development Setup

```bash
# Clone repository
git clone https://github.com/yourusername/enterprise-scorecard.git
cd enterprise-scorecard

# Create development branch
git checkout -b feature/your-feature-name

# Set up virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run in development mode
DEBUG=1 PORT=5005 python3 app1a.py
```

### Code Style

- **Python**: PEP 8 style guide
- **Line Length**: 120 characters max
- **Indentation**: 4 spaces
- **Comments**: Docstrings for all functions

### Adding New Features

1. **Create Issue**: Describe the feature or bug
2. **Branch**: Create feature branch from `main`
3. **Implement**: Write code with tests
4. **Document**: Update README and docstrings
5. **Test**: Verify all phases work
6. **Pull Request**: Submit with detailed description

### Testing

```bash
# Test with sample data
python3 app1a.py

# Navigate to http://localhost:5005
# Use test files from Lego Spain/ or Lego Brazil/

# Verify all phases complete successfully
# Check tracking_reports/ for generated reports
```

### Reporting Issues

Please include:
- **Description**: Clear description of the issue
- **Steps to Reproduce**: Exact steps to reproduce
- **Expected Behavior**: What should happen
- **Actual Behavior**: What actually happens
- **Logs**: Relevant logs from `flask_output.log`
- **Screenshots**: Error screenshots from `error_screenshots/`
- **Environment**: OS, Python version, Chrome version

---

## üìÑ License

This project is licensed under the MIT License.

```
MIT License

Copyright (c) 2026 Arijit Kumar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## üìû Contact & Support

### Project Information

- **Owner**: Arijit Kumar
- **Stakeholders**: Onboarding Team, Customer Success Team
- **Version**: 2.0 (Production)
- **Last Updated**: February 2026

### Resources

- **Documentation**: See additional guides in repository:
  - `HOW_THE_CODE_WORKS.md` - Detailed code walkthrough
  - `STEP_TRACKING_GUIDE.md` - Step tracking system details
  - `COMPREHENSIVE_MONITORING_GUIDE.md` - Monitoring features
  - `HOW_TO_VIEW_LOGS.md` - Log viewing guide
  - `AUTOMATION_SUMMARY.md` - Executive summary

### Quick Links

- **Portal**: https://settings.ef.uk.com
- **Reports**: `tracking_reports/` directory
- **Logs**: `flask_output.log`
- **Screenshots**: `error_screenshots/` directory

---

## üéâ Acknowledgments

Special thanks to:
- Onboarding Team for requirements and testing
- Customer Success Team for feedback and use cases
- QA Team for validation and verification

---

<div align="center">

### Built with ‚ù§Ô∏è for automation efficiency

**[‚¨Ü Back to Top](#enterprise-scorecard-automation)**

</div>
